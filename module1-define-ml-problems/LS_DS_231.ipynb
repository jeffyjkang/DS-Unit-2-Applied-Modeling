{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "BloomTech Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 1*\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define ML problems\n",
    "- Choose a target to predict, and check its distribution\n",
    "- Avoid leakage of information from test to train or from target to features\n",
    "- Choose an appropriate evaluation metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
    "    !pip install category_encoders==2.*\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a target to predict, and check its distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the data science process at a high level:\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/becomingadatascientistadvice-pydatadc-shared-161012184823/95/becoming-a-data-scientist-advice-from-my-podcast-guests-55-638.jpg?cb=1476298295\">\n",
    "\n",
    "—Renee Teate, [Becoming a Data Scientist, PyData DC 2016 Talk](https://www.becomingadatascientist.com/2016/10/11/pydata-dc-2016-talk/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've focused on the 2nd arrow in the diagram, by training predictive models. Now let's zoom out and focus on the 1st arrow: defining problems, by translating business questions into code/data questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last sprint, you did a Kaggle Challenge. It’s a great way to practice model validation and other technical skills. But that's just part of the modeling process. [Kaggle gets critiqued](https://speakerdeck.com/szilard/machine-learning-software-in-practice-quo-vadis-invited-talk-kdd-conference-applied-data-science-track-august-2017-halifax-canada?slide=119) because some things are done for you: Like [**defining the problem!**](https://www.linkedin.com/pulse/data-science-taught-universities-here-why-maciej-wasiak/) In today’s module, you’ll begin to practice this objective, with your dataset you’ve chosen for your personal portfolio project.\n",
    "\n",
    "When defining a supervised machine learning problem, one of the first steps is choosing a target to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which column in your tabular dataset will you predict?\n",
    "\n",
    "Is your problem regression or classification? You have options. Sometimes it’s not straightforward, as we'll see below.\n",
    "\n",
    "- Discrete, ordinal, low cardinality target: Can be regression or multi-class classification.\n",
    "- (In)equality comparison: Converts regression or multi-class classification to binary classification.\n",
    "- Predicted probability: Seems to [blur](https://brohrer.github.io/five_questions_data_science_answers.html) the line between classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reuse the [Burrito reviews dataset.](https://nbviewer.jupyter.org/github/LambdaSchool/DS-Unit-2-Linear-Models/blob/master/module4-logistic-regression/LS_DS_214_assignment.ipynb) 🌯\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Wrangle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "# df = pd.read_csv(DATA_PATH+'burritos/burritos.csv', parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# display(df.shape)\n",
    "# display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What issues do we need to address in our `wrangle` fucniton?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Burrito</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Hunger</th>\n",
       "      <th>Tortilla</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Meat</th>\n",
       "      <th>Fillings</th>\n",
       "      <th>Meat:filling</th>\n",
       "      <th>Uniformity</th>\n",
       "      <th>Salsa</th>\n",
       "      <th>Synergy</th>\n",
       "      <th>Wrap</th>\n",
       "      <th>Reviewer</th>\n",
       "      <th>Unreliable</th>\n",
       "      <th>NonSD</th>\n",
       "      <th>Beef</th>\n",
       "      <th>Pico</th>\n",
       "      <th>Guac</th>\n",
       "      <th>Cheese</th>\n",
       "      <th>Fries</th>\n",
       "      <th>Sour cream</th>\n",
       "      <th>Pork</th>\n",
       "      <th>Chicken</th>\n",
       "      <th>Shrimp</th>\n",
       "      <th>Fish</th>\n",
       "      <th>Rice</th>\n",
       "      <th>Beans</th>\n",
       "      <th>Lettuce</th>\n",
       "      <th>Tomato</th>\n",
       "      <th>Bell peper</th>\n",
       "      <th>Carrots</th>\n",
       "      <th>Cabbage</th>\n",
       "      <th>Sauce</th>\n",
       "      <th>Salsa.1</th>\n",
       "      <th>Cilantro</th>\n",
       "      <th>Onion</th>\n",
       "      <th>Taquito</th>\n",
       "      <th>Pineapple</th>\n",
       "      <th>Ham</th>\n",
       "      <th>Chile relleno</th>\n",
       "      <th>Nopales</th>\n",
       "      <th>Lobster</th>\n",
       "      <th>Egg</th>\n",
       "      <th>Mushroom</th>\n",
       "      <th>Bacon</th>\n",
       "      <th>Sushi</th>\n",
       "      <th>Avocado</th>\n",
       "      <th>Corn</th>\n",
       "      <th>Zucchini</th>\n",
       "      <th>great</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-18</th>\n",
       "      <td>Donato's taco shop</td>\n",
       "      <td>California</td>\n",
       "      <td>6.49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Scott</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-24</th>\n",
       "      <td>Oscar's Mexican food</td>\n",
       "      <td>California</td>\n",
       "      <td>5.45</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Scott</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-24</th>\n",
       "      <td>Oscar's Mexican food</td>\n",
       "      <td>Carnitas</td>\n",
       "      <td>4.85</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Emily</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-24</th>\n",
       "      <td>Oscar's Mexican food</td>\n",
       "      <td>Carne asada</td>\n",
       "      <td>5.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ricardo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-27</th>\n",
       "      <td>Pollos Maria</td>\n",
       "      <td>California</td>\n",
       "      <td>6.59</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Scott</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Location      Burrito  Cost  Hunger  Tortilla  Temp  \\\n",
       "Date                                                                          \n",
       "2016-01-18    Donato's taco shop  California   6.49     3.0       3.0   5.0   \n",
       "2016-01-24  Oscar's Mexican food  California   5.45     3.5       2.0   3.5   \n",
       "2016-01-24  Oscar's Mexican food     Carnitas  4.85     1.5       3.0   2.0   \n",
       "2016-01-24  Oscar's Mexican food  Carne asada  5.25     2.0       3.0   2.0   \n",
       "2016-01-27          Pollos Maria   California  6.59     4.0       4.0   5.0   \n",
       "\n",
       "            Meat  Fillings  Meat:filling  Uniformity  Salsa  Synergy  Wrap  \\\n",
       "Date                                                                         \n",
       "2016-01-18   3.0       3.5           4.0         4.0    4.0      4.0   4.0   \n",
       "2016-01-24   2.5       2.5           2.0         4.0    3.5      2.5   5.0   \n",
       "2016-01-24   2.5       3.0           4.5         4.0    3.0      3.0   5.0   \n",
       "2016-01-24   3.5       3.0           4.0         5.0    4.0      4.0   5.0   \n",
       "2016-01-27   4.0       3.5           4.5         5.0    2.5      4.5   4.0   \n",
       "\n",
       "           Reviewer  Unreliable  NonSD  Beef  Pico  Guac  Cheese  Fries  \\\n",
       "Date                                                                      \n",
       "2016-01-18    Scott           0      0     1     1     1       1      1   \n",
       "2016-01-24    Scott           0      0     1     1     1       1      1   \n",
       "2016-01-24    Emily           0      0     0     1     1       0      0   \n",
       "2016-01-24  Ricardo           0      0     1     1     1       0      0   \n",
       "2016-01-27    Scott           0      0     1     1     0       1      1   \n",
       "\n",
       "            Sour cream  Pork  Chicken  Shrimp  Fish  Rice  Beans  Lettuce  \\\n",
       "Date                                                                        \n",
       "2016-01-18           0     0        0       0     0     0      0        0   \n",
       "2016-01-24           0     0        0       0     0     0      0        0   \n",
       "2016-01-24           0     1        0       0     0     0      0        0   \n",
       "2016-01-24           0     0        0       0     0     0      0        0   \n",
       "2016-01-27           0     0        0       0     0     0      0        0   \n",
       "\n",
       "            Tomato  Bell peper  Carrots  Cabbage  Sauce  Salsa.1  Cilantro  \\\n",
       "Date                                                                         \n",
       "2016-01-18       0           0        0        0      0        0         0   \n",
       "2016-01-24       0           0        0        0      0        0         0   \n",
       "2016-01-24       0           0        0        0      0        0         0   \n",
       "2016-01-24       0           0        0        0      0        0         0   \n",
       "2016-01-27       0           0        0        0      0        0         0   \n",
       "\n",
       "            Onion  Taquito  Pineapple  Ham  Chile relleno  Nopales  Lobster  \\\n",
       "Date                                                                          \n",
       "2016-01-18      0        0          0    0              0        0        0   \n",
       "2016-01-24      0        0          0    0              0        0        0   \n",
       "2016-01-24      0        0          0    0              0        0        0   \n",
       "2016-01-24      0        0          0    0              0        0        0   \n",
       "2016-01-27      0        0          0    0              0        0        0   \n",
       "\n",
       "            Egg  Mushroom  Bacon  Sushi  Avocado  Corn  Zucchini  great  \n",
       "Date                                                                     \n",
       "2016-01-18    0         0      0      0        0     0         0      0  \n",
       "2016-01-24    0         0      0      0        0     0         0      0  \n",
       "2016-01-24    0         0      0      0        0     0         0      0  \n",
       "2016-01-24    0         0      0      0        0     0         0      0  \n",
       "2016-01-27    0         0      0      0        0     0         0      1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wrangle(filepath):\n",
    "    df = pd.read_csv(\n",
    "        filepath,\n",
    "        parse_dates=['Date'],\n",
    "        index_col='Date'\n",
    "    )\n",
    "    \n",
    "    # we need to drop rows with no target\n",
    "    df.dropna(subset=['overall'], inplace=True)   \n",
    "    \n",
    "    # create 'great' column as target\n",
    "    df['great'] = (df['overall'] >= 4).astype(int)\n",
    "    \n",
    "    # drop 'overall' col to avoid leakage\n",
    "    df.drop(columns='overall', inplace=True)\n",
    "    \n",
    "    # fix binary cols\n",
    "    binary_cols = [col for col in df.select_dtypes('object').columns if df[col].nunique() <= 2]\n",
    "    for col in binary_cols:\n",
    "        df[col] = df[col].apply(lambda x: 1 if isinstance(x, str) else 0)\n",
    "    \n",
    "    # drop high-cardinality categorical variables\n",
    "    threshold = 100\n",
    "    high_card_cols = [col for col in df.select_dtypes('object').columns if df[col].nunique() > threshold]\n",
    "    \n",
    "    # drop cols with high number of NaN values\n",
    "    df.dropna(axis=1, thresh=300, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = wrangle(DATA_PATH+'../data/burritos/burritos.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your target \n",
    "\n",
    "Which column in your tabular dataset will you predict?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "target = 'great'\n",
    "y = df[target]\n",
    "X = df.drop(columns=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = '2018'\n",
    "mask = X.index < cutoff\n",
    "X_train, y_train = X.loc[mask], y.loc[mask]\n",
    "X_test, y_test = X.loc[~mask], y.loc[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Establish Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.5822454308093995\n"
     ]
    }
   ],
   "source": [
    "print('Baseline accuracy:', y_train.value_counts(normalize=True).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Build Model\n",
    "\n",
    "Let's build two models: `LogisticRegression` and `RandomForest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix, plot_roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('onehotencoder',\n",
       "                 OneHotEncoder(cols=['Location', 'Burrito', 'Reviewer'],\n",
       "                               use_cat_names=True)),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1: Logistic Regresssion Model\n",
    "model_lr = make_pipeline(\n",
    "    OneHotEncoder(use_cat_names=True),\n",
    "    SimpleImputer(),\n",
    "    StandardScaler(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['Location', 'Burrito', 'Reviewer'],\n",
       "                                mapping=[{'col': 'Location',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': Donato's taco shop           1\n",
       "Oscar's Mexican food         2\n",
       "Pollos Maria                 3\n",
       "Nico's Taco Shop             4\n",
       "Los Primos Mexican Food      5\n",
       "                          ... \n",
       "Taco VIlla                 101\n",
       "Lalo's Tacos               102\n",
       "Kotija Jr                  103\n",
       "Burrito Box                104\n",
       "NaN                         -2\n",
       "Length: 105, dtype: int64},\n",
       "                                         {'col': 'Burrito',\n",
       "                                          'data_type': dtype('...\n",
       "California                4\n",
       "combo chicken             5\n",
       "                       ... \n",
       "Golden State            120\n",
       "Steak fajitas           121\n",
       "Hashbrown               122\n",
       "Steak with guacamole    123\n",
       "NaN                      -2\n",
       "Length: 124, dtype: int64},\n",
       "                                         {'col': 'Reviewer',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': Scott        1\n",
       "Emily        2\n",
       "Ricardo      3\n",
       "Marc         4\n",
       "Nicole       5\n",
       "            ..\n",
       "Erik K      89\n",
       "Simon       90\n",
       "Daniel A    91\n",
       "Nuttida     92\n",
       "Ben S       93\n",
       "Length: 93, dtype: int64}])),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2: Random Forest\n",
    "model_rf = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Check Metrics\n",
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR training accuracy: 1.0\n",
      "LF testing accuracy: 0.7368421052631579\n"
     ]
    }
   ],
   "source": [
    "print('LR training accuracy:', model_lr.score(X_train, y_train))\n",
    "print('LF testing accuracy:', model_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF training accuracy: 1.0\n",
      "RF testing accuracy: 0.7631578947368421\n"
     ]
    }
   ],
   "source": [
    "print('RF training accuracy:', model_rf.score(X_train, y_train))\n",
    "print('RF testing accuracy:', model_rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision and Recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71        16\n",
      "           1       0.80      0.73      0.76        22\n",
      "\n",
      "    accuracy                           0.74        38\n",
      "   macro avg       0.73      0.74      0.73        38\n",
      "weighted avg       0.74      0.74      0.74        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression')\n",
    "print(classification_report(y_test, model_lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71        16\n",
      "           1       0.78      0.82      0.80        22\n",
      "\n",
      "    accuracy                           0.76        38\n",
      "   macro avg       0.76      0.75      0.75        38\n",
      "weighted avg       0.76      0.76      0.76        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest')\n",
    "print(classification_report(y_test, model_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC Curve**\n",
    "\n",
    "- To evaluate models for binary classification.\n",
    "- Decide what probability threshold you should use when making your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffkang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function `plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: RocCurveDisplay.from_predictions or RocCurveDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\jeffkang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function `plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: RocCurveDisplay.from_predictions or RocCurveDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = plot_roc_curve(model_lr, X_test, y_test, label='Logistic')\n",
    "rf = plot_roc_curve(model_rf, X_test, y_test, label='Forest', ax=lr.ax_)\n",
    "plt.plot([(0,0), (1,1)], color='grey', linestyle='--')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR ROC-AUC 0.7386363636363636\n",
      "RF ROC-AUC 0.7528409090909091\n"
     ]
    }
   ],
   "source": [
    "print('LR ROC-AUC', roc_auc_score(y_test, model_lr.predict(X_test)))\n",
    "print('RF ROC-AUC', roc_auc_score(y_test, model_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is your target distributed?\n",
    "\n",
    "For a classification problem, determine: How many classes? Are the classes imbalanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoid leakage of information from test to train or from target to features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting is our enemy in applied machine learning, and leakage is often the cause.\n",
    "\n",
    "> Make sure your training features do not contain data from the “future” (aka time traveling). While this might be easy and obvious in some cases, it can get tricky. … If your test metric becomes really good all of the sudden, ask yourself what you might be doing wrong. Chances are you are time travelling or overfitting in some way. — [Xavier Amatriain](https://www.quora.com/What-are-some-best-practices-for-training-machine-learning-models/answer/Xavier-Amatriain)\n",
    "\n",
    "Choose train, validate, and test sets. Are some observations outliers? Will you exclude them? Will you do a random split or a time-based split? You can (re)read [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, begin to **explore and clean your data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, do a **time-based split:**\n",
    "\n",
    "- Train on reviews from 2016 & earlier. \n",
    "- Validate on 2017. \n",
    "- Test on 2018 & later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin to choose which features, if any, to exclude. **Would some features “leak” future information?**\n",
    "\n",
    "What happens if we _DON’T_ drop features with leakage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the column with “leakage”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How will you evaluate success for your predictive model? You must choose an appropriate evaluation metric, depending on the context and constraints of your problem.\n",
    "\n",
    "**Classification & regression metrics are different!**\n",
    "\n",
    "- Don’t use _regression_ metrics to evaluate _classification_ tasks.\n",
    "- Don’t use _classification_ metrics to evaluate _regression_ tasks.\n",
    "\n",
    "[Scikit-learn has lists of popular metrics.](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification problems: \n",
    "\n",
    "As a rough rule of thumb, if your majority class frequency is >= 50% and < 70% then you can just use accuracy if you want. Outside that range, accuracy could be misleading — so what evaluation metric will you choose, in addition to or instead of accuracy? For example:\n",
    "\n",
    "- Precision?\n",
    "- Recall?\n",
    "- ROC AUC?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision & Recall\n",
    "\n",
    "Let's review Precision & Recall. What do these metrics mean, in scenarios like these?\n",
    "\n",
    "- Predict great burritos\n",
    "- Predict fraudulent transactions\n",
    "- Recommend Spotify songs\n",
    "\n",
    "[Are false positives or false negatives more costly? Can you optimize for dollars?](https://alexgude.com/blog/machine-learning-metrics-interview/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC \n",
    "\n",
    "Let's also review ROC AUC (Receiver Operating Characteristic, Area Under the Curve).\n",
    "\n",
    "[Wikipedia explains,](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) \"A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. **The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.**\"\n",
    "\n",
    "ROC AUC is the area under the ROC curve. [It can be interpreted](https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it) as \"the expectation that a uniformly drawn random positive is ranked before a uniformly drawn random negative.\" \n",
    "\n",
    "ROC AUC measures **how well a classifier ranks predicted probabilities.** So, when you get your classifier’s ROC AUC score, you need to **use predicted probabilities, not discrete predictions.**\n",
    "\n",
    "ROC AUC ranges **from 0 to 1.** Higher is better. A naive majority class **baseline** will have an ROC AUC score of **0.5**, regardless of class (im)balance.\n",
    "\n",
    "#### Scikit-Learn docs\n",
    "- [User Guide: Receiver operating characteristic (ROC)](https://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc)\n",
    "- [sklearn.metrics.roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)\n",
    "- [sklearn.metrics.roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
    "\n",
    "#### More links\n",
    "- [StatQuest video](https://youtu.be/4jRBRDbJemM)\n",
    "- [Data School article / video](https://www.dataschool.io/roc-curves-and-auc-explained/)\n",
    "- [The philosophical argument for using ROC curves](https://lukeoakdenrayner.wordpress.com/2018/01/07/the-philosophical-argument-for-using-roc-curves/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced classes\n",
    "\n",
    "Do you have highly imbalanced classes?\n",
    "\n",
    "If so, you can try ideas from [Learning from Imbalanced Classes](https://www.svds.com/tbt-learning-imbalanced-classes/):\n",
    "\n",
    "- “Adjust the class weight (misclassification costs)” — most scikit-learn classifiers have a `class_balance` parameter.\n",
    "- “Adjust the decision threshold” — we did this last module. Read [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415).\n",
    "- “Oversample the minority class, undersample the majority class, or synthesize new minority classes” — try the the [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library as a stretch goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Regression example 🏘️\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Read our NYC apartment rental listing dataset\n",
    "df = pd.read_csv(DATA_PATH+'apartments/renthop-nyc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your target\n",
    "\n",
    "Which column in your tabular dataset will you predict?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "y = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is your target distributed?\n",
    "\n",
    "For a regression problem, determine: Is the target right-skewed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Yes, the target is right-skewed\n",
    "import seaborn as sns\n",
    "sns.distplot(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are some observations outliers? \n",
    "\n",
    "Will you exclude\n",
    "them?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Yes! There are outliers\n",
    "# Some prices are so high or low it doesn't really make sense.\n",
    "# Some locations aren't even in New York City\n",
    "\n",
    "# Remove the most extreme 1% prices, \n",
    "# the most extreme .1% latitudes, &\n",
    "# the most extreme .1% longitudes\n",
    "import numpy as np\n",
    "df = df[(df['price'] >= np.percentile(df['price'], 0.5)) & \n",
    "        (df['price'] <= np.percentile(df['price'], 99.5)) & \n",
    "        (df['latitude'] >= np.percentile(df['latitude'], 0.05)) & \n",
    "        (df['latitude'] < np.percentile(df['latitude'], 99.95)) &\n",
    "        (df['longitude'] >= np.percentile(df['longitude'], 0.05)) & \n",
    "        (df['longitude'] <= np.percentile(df['longitude'], 99.95))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distribution has improved, but is still right-skewed\n",
    "y = df['price']\n",
    "sns.distplot(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Transform\n",
    "\n",
    "If the target is right-skewed, you may want to “log transform” the target.\n",
    "\n",
    "\n",
    "> Transforming the target variable (using the mathematical log function) into a tighter, more uniform space makes life easier for any [regression] model.\n",
    ">\n",
    "> The only problem is that, while easy to execute, understanding why taking the log of the target variable works and how it affects the training/testing process is intellectually challenging. You can skip this section for now, if you like, but just remember that this technique exists and check back here if needed in the future.\n",
    ">\n",
    "> Optimally, the distribution of prices would be a narrow “bell curve” distribution without a tail. This would make predictions based upon average prices more accurate. We need a mathematical operation that transforms the widely-distributed target prices into a new space. The “price in dollars space” has a long right tail because of outliers and we want to squeeze that space into a new space that is normally distributed. More specifically, we need to shrink large values a lot and smaller values a little. That magic operation is called the logarithm or log for short. \n",
    ">\n",
    "> To make actual predictions, we have to take the exp of model predictions to get prices in dollars instead of log dollars. \n",
    ">\n",
    ">— Terence Parr & Jeremy Howard, [The Mechanics of Machine Learning, Chapter 5.5](https://mlbook.explained.ai/prep.html#logtarget)\n",
    "\n",
    "[Numpy has exponents and logarithms](https://docs.scipy.org/doc/numpy/reference/routines.math.html#exponents-and-logarithms). Your Python code could look like this:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "y_train_log = np.log1p(y_train)\n",
    "model.fit(X_train, y_train_log)\n",
    "y_pred_log = model.predict(X_val)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "print(mean_absolute_error(y_val, y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y)\n",
    "plt.title('Original target, in the unit of US dollars');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = np.log1p(y)\n",
    "sns.distplot(y_log)\n",
    "plt.title('Log-transformed target, in log-dollars');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_untransformed = np.expm1(y_log)\n",
    "sns.distplot(y_untransformed)\n",
    "plt.title('Back to the original units');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You will use your portfolio project dataset for all assignments this sprint. (If you haven't found a dataset yet, do that today. [Review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2) and choose your dataset.)\n",
    "\n",
    "Complete these tasks for your project, and document your decisions.\n",
    "\n",
    "- Choose your target. Which column in your tabular dataset will you predict?\n",
    "- Is your problem regression or classification?\n",
    "- How is your target distributed?\n",
    "    - Classification: How many classes? Are the classes imbalanced?\n",
    "    - Regression: Is the target right-skewed? If so, you may want to log transform the target.\n",
    "- Choose your evaluation metric(s).\n",
    "    - Classification: Is your majority class frequency >= 50% and < 70% ? If so, you can just use accuracy if you want. Outside that range, accuracy could be misleading. What evaluation metric will you choose, in addition to or instead of accuracy?\n",
    "    - Regression: Will you use mean absolute error, root mean squared error, R^2, or other regression metrics?\n",
    "- Choose which observations you will use to train, validate, and test your model.\n",
    "    - Are some observations outliers? Will you exclude them?\n",
    "    - Will you do a random split or a time-based split?\n",
    "- Begin to clean and explore your data.\n",
    "- Begin to choose which features, if any, to exclude. Would some features \"leak\" future information?\n",
    "\n",
    "Some students worry, ***what if my model isn't “good”?*** Then, [produce a detailed tribute to your wrongness. That is science!](https://twitter.com/nathanwpyle/status/1176860147223867393)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
