{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2ha9OWxf0jw"
   },
   "source": [
    "BloomTech Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-hTictxWYih7"
   },
   "source": [
    "# Permutation & Boosting\n",
    "\n",
    "- Get **permutation importances** for model interpretation and feature selection\n",
    "- Use xgboost for **gradient boosting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMejJg0w8v76"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the code cell below. You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab.\n",
    "\n",
    "Libraries:\n",
    "\n",
    "- category_encoders\n",
    "- [**eli5**](https://eli5.readthedocs.io/en/latest/)\n",
    "- matplotlib\n",
    "- numpy\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- [**xgboost**](https://xgboost.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFQMky3CYih-"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
    "    !pip install category_encoders==2.*\n",
    "    !pip install eli5\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll go back to Tanzania Waterpumps for this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z-TExplb_Slf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Merge train_features.csv & train_labels.csv\n",
    "# train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
    "#                  pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
    "df = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv', na_values=[0, -2.000000e-08]), \n",
    "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv')).set_index('id')\n",
    "\n",
    "# Read test_features.csv & sample_submission.csv\n",
    "# test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
    "# sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
    "\n",
    "\n",
    "# Split train into train & val\n",
    "# train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
    "#                               stratify=train['status_group'], random_state=42)\n",
    "\n",
    "\n",
    "def wrangle(X):\n",
    "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
    "    \n",
    "    # Prevent SettingWithCopyWarning\n",
    "    X = X.copy()\n",
    "    \n",
    "    # high cardinality\n",
    "    high_card_cols = [col for col in X.select_dtypes('object').columns if X[col].nunique() > 100]\n",
    "    X.drop(columns=high_card_cols, inplace=True)\n",
    "    \n",
    "    # repeasted cols\n",
    "    cols = ['extraction_type_group', 'quantity']\n",
    "    X.drop(columns=cols, inplace=True)\n",
    "    \n",
    "    # About 3% of the time, latitude has small values near zero,\n",
    "    # outside Tanzania, so we'll treat these values like zero.\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
    "    \n",
    "    # When columns have zeros and shouldn't, they are like null values.\n",
    "    # So we will replace the zeros with nulls, and impute missing values later.\n",
    "    # Also create a \"missing indicator\" column, because the fact that\n",
    "    # values are missing may be a predictive signal.\n",
    "#     cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
    "#                        'gps_height', 'population']\n",
    "#     for col in cols_with_zeros:\n",
    "#         X[col] = X[col].replace(0, np.nan)\n",
    "#         X[col+'_MISSING'] = X[col].isnull()\n",
    "            \n",
    "    # Drop duplicate columns\n",
    "#     duplicates = ['quantity_group', 'payment_type']\n",
    "#     X = X.drop(columns=duplicates)\n",
    "    \n",
    "    # Drop recorded_by (never varies) and id (always varies, random)\n",
    "#     unusable_variance = ['recorded_by', 'id']\n",
    "#     X = X.drop(columns=unusable_variance)\n",
    "    \n",
    "    # Convert date_recorded to datetime\n",
    "#     X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "    \n",
    "    # Extract components from date_recorded, then drop the original column\n",
    "#     X['year_recorded'] = X['date_recorded'].dt.year\n",
    "#     X['month_recorded'] = X['date_recorded'].dt.month\n",
    "#     X['day_recorded'] = X['date_recorded'].dt.day\n",
    "#     X = X.drop(columns='date_recorded')\n",
    "    \n",
    "    # Engineer feature: how many years from construction_year to date_recorded\n",
    "#     X['years'] = X['year_recorded'] - X['construction_year']\n",
    "#     X['years_MISSING'] = X['years'].isnull()\n",
    "    \n",
    "    # return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "df = wrangle(df)\n",
    "# train = wrangle(train)\n",
    "# val = wrangle(val)\n",
    "# test = wrangle(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhg8PQKt_jzP"
   },
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector\n",
    "target = 'status_group'\n",
    "# X_train = train.drop(columns=target)\n",
    "# y_train = train[target]\n",
    "# X_val = val.drop(columns=target)\n",
    "# y_val = val[target]\n",
    "# X_test = test\n",
    "y = df[target]\n",
    "X = df.drop(target, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5425829668132747\n"
     ]
    }
   ],
   "source": [
    "print('Baseline Accuracy:', y_train.value_counts(normalize=True).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bagging**: Random Forest, multiple trees, subsets, in parallel\n",
    "\n",
    "**Boosting**: Gradient Boosting Trees, multiple trees, all the data, in sequence\n",
    "- residuals: R = y - ^y\n",
    "- fit(X,y) -> fit(X,R_1) -> fit(X,R_2) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8lB4z5l_eml"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['basin', 'region', 'public_meeting',\n",
       "                                      'recorded_by', 'scheme_management',\n",
       "                                      'permit', 'extraction_type',\n",
       "                                      'extraction_type_class', 'management',\n",
       "                                      'management_group', 'payment',\n",
       "                                      'payment_type', 'water_quality',\n",
       "                                      'quality_group', 'quantity_group',\n",
       "                                      'source', 'source_type', 'source_class',\n",
       "                                      'waterpoint_type',\n",
       "                                      'waterpoint_ty...\n",
       "hand pump                      2\n",
       "other                          3\n",
       "communal standpipe multiple    4\n",
       "improved spring                5\n",
       "cattle trough                  6\n",
       "dam                            7\n",
       "NaN                           -2\n",
       "dtype: int64},\n",
       "                                         {'col': 'waterpoint_type_group',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': communal standpipe    1\n",
       "hand pump             2\n",
       "other                 3\n",
       "improved spring       4\n",
       "cattle trough         5\n",
       "dam                   6\n",
       "NaN                  -2\n",
       "dtype: int64}])),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('gradientboostingclassifier',\n",
       "                 GradientBoostingClassifier(random_state=42))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import category_encoders as ce\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_skgb = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    GradientBoostingClassifier(random_state=42)\n",
    ")\n",
    "\n",
    "# pipeline = make_pipeline(\n",
    "#     ce.OrdinalEncoder(), \n",
    "#     SimpleImputer(strategy='median'), \n",
    "#     RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "# )\n",
    "\n",
    "# Fit on train, score on val\n",
    "# pipeline.fit(X_train, y_train)\n",
    "# print('Validation Accuracy', pipeline.score(X_val, y_val))\n",
    "model_skgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffkang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:16:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"eval_set\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['basin', 'region', 'public_meeting',\n",
       "                                      'recorded_by', 'scheme_management',\n",
       "                                      'permit', 'extraction_type',\n",
       "                                      'extraction_type_class', 'management',\n",
       "                                      'management_group', 'payment',\n",
       "                                      'payment_type', 'water_quality',\n",
       "                                      'quality_group', 'quantity_group',\n",
       "                                      'source', 'source_type', 'source_class',\n",
       "                                      'waterpoint_type',\n",
       "                                      'waterpoint_ty...\n",
       "                               gamma=0, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=400,\n",
       "                               n_jobs=-1, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=None, subsample=1,\n",
       "                               tree_method='exact', ...))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(X_val, y_val)]\n",
    "\n",
    "model_xgb = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    XGBClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_set=eval_set,\n",
    "        eval_metric='merror',\n",
    "        early_stopping_rounds=10,\n",
    "        n_estimators=400,\n",
    "        verbose=True\n",
    "    )\n",
    ")\n",
    "model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Training Accuracy: 0.7505629327216482\n",
      "sklearn Validation Accuracy: 0.7522727272727273\n"
     ]
    }
   ],
   "source": [
    "print('sklearn Training Accuracy:', model_skgb.score(X_train, y_train))\n",
    "print('sklearn Validation Accuracy:', model_skgb.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training Accuracy: 0.8408636545381847\n",
      "XGBoost Validation Accuracy: 0.7988215488215489\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('XGBoost Training Accuracy:', model_xgb.score(X_train, y_train))\n",
    "print('XGBoost Validation Accuracy:', model_xgb.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training Accuracy: 0.918685157515941\n",
      "XGBoost Validation Accuracy: 0.8067340067340067\n"
     ]
    }
   ],
   "source": [
    "print('XGBoost Training Accuracy:', model_xgb.score(X_train, y_train))\n",
    "print('XGBoost Validation Accuracy:', model_xgb.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communicate Results\n",
    "- How can we determine or communicate which features are most important to our model when making predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1**: Grab feature importances from our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = model_skgb.named_steps['gradientboostingclassifier'].feature_importances_\n",
    "\n",
    "feat_imp = pd.Series(importances, index=X_train.columns).sort_values()\n",
    "feat_imp.tail(10).plot(kind='barh')\n",
    "plt.xlabel('Gini importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature importance for model_skgb');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2**: Drop-column Importance\n",
    "- Good, but computationally expensive because you have to train a model for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffkang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:23:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Validaiton accuracy with \"quantity_group\" included: 0.7554713804713805\n"
     ]
    }
   ],
   "source": [
    "# step 1: train a model with the feature whose importance we want to evaluate\n",
    "feature = 'quantity_group'\n",
    "\n",
    "model_w_feat = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    XGBClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        n_estimators=10,\n",
    "    )\n",
    ")\n",
    "model_w_feat.fit(X_train, y_train);\n",
    "print(f'Validaiton accuracy with \"{feature}\" included:', model_w_feat.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffkang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:24:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Validaiton accuracy without \"quantity_group\" included: 0.7198653198653199\n"
     ]
    }
   ],
   "source": [
    "# step 2: train a model without the feature we want to evaluate\n",
    "\n",
    "model_wo_feat = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    XGBClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        n_estimators=10,\n",
    "    )\n",
    ")\n",
    "\n",
    "model_wo_feat.fit(X_train.drop(columns=feature), y_train);\n",
    "print(f'Validaiton accuracy without \"{feature}\" included:', model_wo_feat.score(X_val.drop(columns=feature), y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 3**: Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffkang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:31:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Validation Accuracy 0.7554713804713805\n"
     ]
    }
   ],
   "source": [
    "# by hand\n",
    "from numpy.random import permutation\n",
    "\n",
    "# our feature will still be 'quantity_group'\n",
    "\n",
    "# step 1: train model on whole dataset\n",
    "model_xgb = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    XGBClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        n_estimators=10,\n",
    "    )\n",
    ")\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# step 2: evaluate using the validation set\n",
    "print('Validation Accuracy', model_xgb.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "37098.0             dry\n",
       "14530.0    insufficient\n",
       "71755.0          enough\n",
       "55610.0          enough\n",
       "19821.0          enough\n",
       "Name: quantity_group, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "37098.0          enough\n",
       "14530.0             dry\n",
       "71755.0    insufficient\n",
       "55610.0          enough\n",
       "19821.0         unknown\n",
       "Name: quantity_group, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step 3: in our validation set, permute the feature we're evaluating\n",
    "X_val_perm = X_val.copy()\n",
    "X_val_perm[feature] = permutation(X_val[feature])\n",
    "\n",
    "display(X_val[feature].head())\n",
    "display(X_val_perm[feature].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy with \"quantity_group\" permuted 0.6583333333333333\n"
     ]
    }
   ],
   "source": [
    "# step 4: calculate the error metric with the permuted data\n",
    "print(f'Validation Accuracy with \"{feature}\" permuted', model_xgb.score(X_val_perm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sklearn\n",
    "from sklearn.inspection import permutation_importance\n",
    "perm_imp = permutation_importance(\n",
    "    model_xgb,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['importances_mean', 'importances_std', 'importances'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(type(perm_imp))\n",
    "display(perm_imp.keys())\n",
    "# put into df\n",
    "data = {'importances_mean': perm_imp['importances_mean'],\n",
    "       'importances_std': perm_imp['importances_std']}\n",
    "\n",
    "df = pd.DataFrame(data, index=X_val.columns)\n",
    "df.sort_values(by='importances_mean', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Permutation importance for model_xgb')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['importances_mean'].tail(10).plot(kind='barh')\n",
    "plt.xlabel('Importance (drop in accuracy)')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Permutation importance for model_xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get permutation importances for model interpretation and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default Feature Importances are fast, but Permutation Importances may be more accurate.\n",
    "\n",
    "These links go deeper with explanations and examples:\n",
    "\n",
    "- Permutation Importances\n",
    "  - [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)\n",
    "  - [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
    "- (Default) Feature Importances\n",
    "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
    "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HOayKBOYiit"
   },
   "source": [
    "There are three types of feature importances:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4bRhsxENYiiu"
   },
   "source": [
    "### 1. (Default) Feature Importances\n",
    "\n",
    "Fastest, good for first estimates, but be aware:\n",
    "\n",
    "\n",
    "\n",
    ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable.  [Selecting good features  Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) \n",
    "\n",
    "\n",
    " \n",
    " > **The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables.** ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of adding up the gini decreases for each individual variable over all trees in the forest gives a **fast** variable importance that is often very consistent with the permutation importance measure.   [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNVm6f7mYiiu"
   },
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "rf = pipeline.named_steps['randomforestclassifier']\n",
    "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
    "\n",
    "# Plot feature importances\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 20\n",
    "plt.figure(figsize=(10,n/2))\n",
    "plt.title(f'Top {n} features')\n",
    "importances.sort_values()[-n:].plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8HzLcCBYiiv"
   },
   "source": [
    "### 2. Drop-Column Importance\n",
    "\n",
    "The best in theory, but too slow in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQAOlERnYiiw"
   },
   "outputs": [],
   "source": [
    "column  = 'quantity'\n",
    "\n",
    "# Fit without column\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "pipeline.fit(X_train.drop(columns=column), y_train)\n",
    "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
    "print(f'Validation Accuracy without {column}: {score_without}')\n",
    "\n",
    "# Fit with column\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "score_with = pipeline.score(X_val, y_val)\n",
    "print(f'Validation Accuracy with {column}: {score_with}')\n",
    "\n",
    "# Compare the error with & without column\n",
    "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Vu39wGkYiix"
   },
   "source": [
    "### 3. Permutation Importance\n",
    "\n",
    "Permutation Importance is a good compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
    "\n",
    "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
    "\n",
    "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score were interested in) decreases when a feature is not available.\n",
    ">\n",
    "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
    ">\n",
    ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesnt work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples feature values - this is how permutation importance is computed.\n",
    ">\n",
    ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYCiEx7zYiiy"
   },
   "source": [
    "### Do-It-Yourself way, for intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TksOf_n2Yiiy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LYk19SNYii7"
   },
   "source": [
    "### With eli5 library\n",
    "\n",
    "For more documentation on using this library, see:\n",
    "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
    "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)\n",
    "- [scikit-learn user guide, `scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
    "\n",
    "eli5 doesn't work with pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpSemTkFFP8i"
   },
   "outputs": [],
   "source": [
    "# Ignore warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q07yW9k-Yii8"
   },
   "source": [
    "### We can use importances for feature selection\n",
    "\n",
    "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZrPFyEMYii9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fl67bCR7WY6j"
   },
   "source": [
    "# Use xgboost for gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Random Forest lesson, you learned this advice:\n",
    "\n",
    "#### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
    "- \"Tree Ensembles\" means Random Forest or **Gradient Boosting** models. \n",
    "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
    "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
    "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or **[boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)** (Gradient Boosting).\n",
    "- Random Forest's advantage: may be less sensitive to hyperparameters. **Gradient Boosting's advantage:** may get better predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like Random Forest, Gradient Boosting uses ensembles of trees. But the details of the ensembling technique are different:\n",
    "\n",
    "### Understand the difference between boosting & bagging\n",
    "\n",
    "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
    "\n",
    "Here's an excerpt from [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
    "\n",
    ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
    ">\n",
    ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
    ">\n",
    ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
    ">\n",
    ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve f in areas where it does not perform well.**\n",
    ">\n",
    ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown.\n",
    "\n",
    "This high-level overview is all you need to know for now. If you want to go deeper, we recommend you watch the StatQuest videos on gradient boosting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write some code. We have lots of options for which libraries to use:\n",
    "\n",
    "#### Python libraries for Gradient Boosting\n",
    "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting)  slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
    "  - Anaconda: already installed\n",
    "  - Google Colab: already installed\n",
    "- [xgboost](https://xgboost.readthedocs.io/en/latest/) can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
    "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
    "  - Windows: `conda install -c anaconda py-xgboost`\n",
    "  - Google Colab: already installed\n",
    "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
    "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
    "  - Google Colab: already installed\n",
    "- [CatBoost](https://catboost.ai/) can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
    "  - Anaconda: `conda install -c conda-forge catboost`\n",
    "  - Google Colab: `pip install catboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, you'll use a new library, xgboost But it has an API that's almost the same as scikit-learn, so it won't be a hard adjustment!\n",
    "\n",
    "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsnJRKjfWYph"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCjVSlD_XJr2"
   },
   "source": [
    "#### [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)\n",
    "\n",
    "Why is early stopping better than a For loop, or GridSearchCV, to optimize `n_estimators`?\n",
    "\n",
    "With early stopping, if `n_iterations` is our number of iterations, then we fit `n_iterations` decision trees.\n",
    "\n",
    "With a for loop, or GridSearchCV, we'd fit `sum(range(1,n_rounds+1))` trees.\n",
    "\n",
    "But it doesn't work well with pipelines. You may need to re-run multiple times with different values of other parameters such as `max_depth` and `learning_rate`.\n",
    "\n",
    "#### XGBoost parameters\n",
    "- [Notes on parameter tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
    "- [Parameters documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNX3IKftXBFS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZF7-ml6BhRRf"
   },
   "source": [
    "### Try adjusting these hyperparameters\n",
    "\n",
    "#### Random Forest\n",
    "- class_weight (for imbalanced classes)\n",
    "- max_depth (usually high, can try decreasing)\n",
    "- n_estimators (too low underfits, too high wastes time)\n",
    "- min_samples_leaf (increase if overfitting)\n",
    "- max_features (decrease for more diverse trees)\n",
    "\n",
    "#### Xgboost\n",
    "- scale_pos_weight (for imbalanced classes)\n",
    "- max_depth (usually low, can try increasing)\n",
    "- n_estimators (too low underfits, too high wastes time/overfits)  Use Early Stopping!\n",
    "- learning_rate (too low underfits, too high overfits)\n",
    "\n",
    "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You will use your portfolio project dataset for all assignments this sprint. Complete these tasks for your project, and document your work.\n",
    "\n",
    "- Continue to clean and explore your data. Make exploratory visualizations.\n",
    "- Fit a model. Does it beat your baseline?\n",
    "- Try xgboost.\n",
    "- Get your model's permutation importances.\n",
    "\n",
    "You should try to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
    "\n",
    "But, if you aren't ready to try xgboost and permutation importances with your dataset today, you can practice with another dataset instead. You may choose any dataset you've worked with previously."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
